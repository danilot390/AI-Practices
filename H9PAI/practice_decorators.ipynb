{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logging APi Calls\n",
    "In a microservices architecture, you might want lo log all API request for monitoring and debugging.\n",
    "\n",
    "* Use a decorator to log the details of the API calls dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Request: fetch_data_from_api | args: ('https://jsonplaceholder.typicode.com/posts',), kwargs: {'params': {'userId': 1}}\n",
      "Api Response: 200 | [\n",
      "  {\n",
      "    \"userId\": 1,\n",
      "    \"id\": 1,\n",
      "    \"title\": \"sunt aut facere repellat provident occaecati excep\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Logging decorator for API calls.\n",
    "def api_logger(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f'API Request: {func.__name__} | args: {args}, kwargs: {kwargs}')\n",
    "        response = func(*args, **kwargs)\n",
    "        print(f'Api Response: {response.status_code} | {response.text[:100]}')\n",
    "        return response\n",
    "    return wrapper\n",
    "\n",
    "@api_logger\n",
    "def fetch_data_from_api(url, params=None):\n",
    "    return requests.get(url, params=params)\n",
    "\n",
    "# Use case: Fetch data from an API\n",
    "fetch_data_from_api('https://jsonplaceholder.typicode.com/posts', params={'userId': 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Processing Large Log Files\n",
    "Image you need to analize gigabytes of server logs without loading them entirely into memory.\n",
    "\n",
    "* Use a generator to process the log file line by line.\n",
    "\n",
    "*Best Practice.* Generators allow you process large files efficiently without exhausting memory.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator to read a log file line by line.\n",
    "def read_log_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            yield line.strip()\n",
    "\n",
    "# Use case: Search for error messages in the log.\n",
    "for log_line in read_log_file('server.log'):\n",
    "    if 'Error' in log_line:\n",
    "        print(log_line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Validation in ETL Pipeline\n",
    "In an ETL(Extract, Transform, Load) pipeline, you might want to validate data records dynamically before processing them.\n",
    "\n",
    "__Solution with Decorators and Generators__\n",
    "Combine decorators and generators for efficient fata handling.\n",
    "\n",
    "__Best Practice:__ This aproach dynamically validates data while efficiently handling large datasets with generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'processed_value': 20}\n",
      "invalid record skipped: {'id': None, 'value': 20}\n",
      "{'id': 2, 'processed_value': 60}\n"
     ]
    }
   ],
   "source": [
    "# Validate decorator.\n",
    "def validate_record(func):\n",
    "    def wrapper(record):\n",
    "        if not record.get('id') or not record.get('value'):\n",
    "            print(f'invalid record skipped: {record}')\n",
    "            return None\n",
    "        return func(record)\n",
    "    return wrapper\n",
    "\n",
    "# Generator for porcessing records.\n",
    "@validate_record\n",
    "def process_record(record):\n",
    "    # Simulate processing\n",
    "    return {'id': record['id'], 'processed_value': record['value']*2}\n",
    "\n",
    "# Use case: Process records from a large dataset\n",
    "def record_stream(data):\n",
    "    for record in data:\n",
    "        processed = process_record(record)\n",
    "        if processed:\n",
    "            yield processed\n",
    "\n",
    "# Simulated large dataset\n",
    "dataset = [\n",
    "    {'id': 1, 'value': 10},\n",
    "    {'id': None, 'value': 20}, # Invalid\n",
    "    {'id': 2, 'value': 30}\n",
    "]\n",
    "\n",
    "for processed_record in record_stream(dataset):\n",
    "    print(processed_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Rate-Limiting Function Calls\n",
    "In APIs or automation scripts, you might want to limit the number of function calls to prevent overloading the system.\n",
    "\n",
    "__Use a decorator to throttle function calls.__\n",
    "\n",
    "__Best Practice.__ The decorator centralizes rate-limiting logic, making it easy to apply across multiple functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request sent at 1736360072.753134\n",
      "Request sent at 1736360073.258177\n",
      "Request sent at 1736360073.7619781\n",
      "Request sent at 1736360074.267002\n",
      "Request sent at 1736360074.7720268\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Rate-limiting decorator\n",
    "def rate_limiter(max_calls_per_second):\n",
    "    interval = 1/ max_calls_per_second\n",
    "    last_call_time = [0]\n",
    "\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            elapsed = time.time() - last_call_time[0]\n",
    "            if elapsed < interval:\n",
    "                time.sleep(interval-elapsed)\n",
    "            last_call_time[0] = time.time()\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@rate_limiter(2) # Allow two calls per second\n",
    "def send_request():\n",
    "    print(f'Request sent at {time.time()}')\n",
    "\n",
    "# Use case: Simulate sending requests\n",
    "for _ in range(5):\n",
    "    send_request()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Streaming data Analysis\n",
    "for real-time analytics, you might need to analyze streams of data (e.g., from sensors or Kafka topics).\n",
    "\n",
    "* Use generator to process the data stream as it arrives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High value alert: {'sensor_id': 1, 'value': 86, 'timestamp': 1736360262.23959}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Simulate delay\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Use case: Process the stream.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHigh value alert: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36mdata_stream\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensor_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m:random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m:time\u001b[38;5;241m.\u001b[39mtime()}\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time \n",
    "\n",
    "# Simulate a live data stream\n",
    "def data_stream():\n",
    "    while True:\n",
    "        yield {'sensor_id': 1, 'value':random.randint(0, 100), 'timestamp':time.time()}\n",
    "        time.sleep(1) # Simulate delay\n",
    "\n",
    "# Use case: Process the stream.\n",
    "for data in data_stream():\n",
    "    if data['value'] > 80:\n",
    "        print(f'High value alert: {data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
